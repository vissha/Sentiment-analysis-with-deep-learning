{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e8620b",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9b4649df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5fcd5d",
   "metadata": {},
   "source": [
    "## loading data and splitting into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "194d1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_process_data.csv') #In new_process_data i just combine text data columns into one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c582bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['text'].values\n",
    "y=df['Rating'].values\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.33 , stratify=y , random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51170b",
   "metadata": {},
   "source": [
    "## Checking different features for best test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c00b3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(x_train , x_test , y_train , y_test , verbose , mode):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_matrix(x_train,mode = mode)\n",
    "    X_test = tokenizer.texts_to_matrix(x_test,mode = mode)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50 , input_shape = (X_train.shape[1],) , activation = 'relu'))\n",
    "    model.add(Dense(1 , activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy' , optimizer = 'adam' , metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "\n",
    "    model.fit(X_train , y_train , epochs=10 , verbose=verbose)\n",
    "\n",
    "    loss , acc = model.evaluate(X_test , y_test , verbose=verbose)\n",
    "\n",
    "    #print('#'*50)\n",
    "\n",
    "    print('Test accuracy for ' + mode + ' is = ' , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b17cba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for freq is =  0.9397357106208801\n",
      "Test accuracy for binary is =  0.9318061470985413\n",
      "Test accuracy for tfidf is =  0.9318061470985413\n",
      "Test accuracy for count is =  0.932511031627655\n"
     ]
    }
   ],
   "source": [
    "modes = ['freq' , 'binary' , 'tfidf' , 'count']\n",
    "for i in modes:\n",
    "    training_model(x_train , x_test , y_train , y_test , 0 , i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a68ea",
   "metadata": {},
   "source": [
    "### As we get to know freq provide us best test accuracy now lets train our actual model but before training it don't forget to run first three cells because we don't want our tokenizer to learn similar words again and again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd69db4",
   "metadata": {},
   "source": [
    "## Running our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bef41e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_training_model(x_train , x_test , y_train , y_test , verbose , mode):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_matrix(x_train,mode = mode)\n",
    "    X_test = tokenizer.texts_to_matrix(x_test,mode = mode)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50 , input_shape = (X_train.shape[1],) , activation = 'relu'))\n",
    "    model.add(Dense(1 , activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy' , optimizer = 'adam' , metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    model.fit(X_train , y_train , epochs=10 , verbose=verbose)\n",
    "\n",
    "    loss , acc = model.evaluate(X_test , y_test , verbose=verbose)\n",
    "\n",
    "    print('#'*50)\n",
    "\n",
    "    print('Test accuracy for ' + mode + ' is = ' , acc)\n",
    "    \n",
    "    return tokenizer , model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b6a14441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 50)                902250    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 902,301\n",
      "Trainable params: 902,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "360/360 - 3s - loss: 0.4039 - accuracy: 0.8796\n",
      "Epoch 2/10\n",
      "360/360 - 2s - loss: 0.2870 - accuracy: 0.8815\n",
      "Epoch 3/10\n",
      "360/360 - 2s - loss: 0.2053 - accuracy: 0.9069\n",
      "Epoch 4/10\n",
      "360/360 - 2s - loss: 0.1524 - accuracy: 0.9391\n",
      "Epoch 5/10\n",
      "360/360 - 2s - loss: 0.1252 - accuracy: 0.9522\n",
      "Epoch 6/10\n",
      "360/360 - 2s - loss: 0.1070 - accuracy: 0.9610\n",
      "Epoch 7/10\n",
      "360/360 - 2s - loss: 0.0939 - accuracy: 0.9665\n",
      "Epoch 8/10\n",
      "360/360 - 2s - loss: 0.0829 - accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "360/360 - 2s - loss: 0.0733 - accuracy: 0.9767\n",
      "Epoch 10/10\n",
      "360/360 - 2s - loss: 0.0655 - accuracy: 0.9799\n",
      "178/178 - 1s - loss: 0.1560 - accuracy: 0.9371\n",
      "##################################################\n",
      "Test accuracy for freq is =  0.9370924830436707\n"
     ]
    }
   ],
   "source": [
    "our_tokenizer , our_model = final_training_model(x_train , x_test , y_train , y_test , 2 , 'freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0199f12",
   "metadata": {},
   "source": [
    "## Making Prediction for future review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1da4f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review : [it is worst product try to avoid it you can find other options]\n",
      "Sentiment : NEGATIVE (80.180%)\n",
      "\n",
      "Review : [great one go for it]\n",
      "Sentiment : POSITIVE (99.983%)\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(r_text):\n",
    "    encoded = our_tokenizer.texts_to_matrix([r_text] , mode = 'freq')\n",
    "    yhat = our_model.predict(encoded , verbose = 0)\n",
    "    percent_pos = yhat[0,0]\n",
    "    if round(percent_pos) == 0:\n",
    "        return (1-percent_pos) , 'NEGATIVE'\n",
    "    return percent_pos , 'POSITIVE'\n",
    "    \n",
    "    \n",
    "text = 'it is worst product try to avoid it you can find other options'\n",
    "percent , sentiment = predict_sentiment(text)\n",
    "print('Review : [%s]\\nSentiment : %s (%.3f%%)\\n' %(text , sentiment , percent*100))\n",
    "\n",
    "text = 'great one go for it'\n",
    "percent , sentiment = predict_sentiment(text)\n",
    "print('Review : [%s]\\nSentiment : %s (%.3f%%)' %(text , sentiment , percent*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb23ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab8051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
